{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPekwnNrTqzkD5Ai0Uj5J4b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamelof23/ASL2/blob/main/ASL2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload dataset"
      ],
      "metadata": {
        "id": "pUOBb1nVwTyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload archive.zip to /content/sample_data/"
      ],
      "metadata": {
        "id": "5eXt1gToxNf7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unzip the Dataset"
      ],
      "metadata": {
        "id": "qFMLQcgOwgQX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLe8-fFDehIb"
      },
      "outputs": [],
      "source": [
        "!unzip /content/sample_data/archive.zip -d /content/asl_alphabet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Organizing and Sorting the data"
      ],
      "metadata": {
        "id": "JIZYrVAK_Ol-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create folders for each class in the test directory and move the images into their respective folders. For training data its already sorted."
      ],
      "metadata": {
        "id": "GSL886HUE0xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "test_dir = '/content/asl_alphabet/asl_alphabet_test/asl_alphabet_test/'\n",
        "\n",
        "# Define the classes\n",
        "class_names = ['A', 'B', 'C', 'D', 'del', 'E', 'F', 'G', 'H', 'I',\n",
        "               'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S',\n",
        "               'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'nothing', 'space']\n",
        "\n",
        "# Create directories for each class in the test directory\n",
        "for class_name in class_names:\n",
        "    os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)\n",
        "\n",
        "# Move each test image into the appropriate class folder\n",
        "for image_name in os.listdir(test_dir):\n",
        "    if '_test.jpg' in image_name:\n",
        "        class_name = image_name.split('_')[0]  # Get the class from the image name\n",
        "        shutil.move(os.path.join(test_dir, image_name),\n",
        "                    os.path.join(test_dir, class_name, image_name))"
      ],
      "metadata": {
        "id": "THuxXIF__lSR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the training and testing datasets"
      ],
      "metadata": {
        "id": "G9wVXmEywvdx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Batch Size\n",
        "Definition: The batch size refers to the number of training examples used in one iteration of training.\n",
        "Purpose: Instead of updating the model weights after each individual sample, which can be computationally expensive and lead to noisy updates, the model processes a batch of samples and computes the gradient based on that batch. This approach helps to stabilize the training process and can lead to faster convergence.\n",
        "Common Values: Common batch sizes are powers of 2 (like 32, 64, 128) since they can be more efficient for hardware acceleration (e.g., GPUs).\n",
        "2. Reproducibility\n",
        "Definition: Reproducibility refers to the ability to achieve the same results when you run the experiment multiple times under the same conditions.\n",
        "Purpose: In machine learning, due to the stochastic nature of algorithms (like random initialization of weights or shuffling of data), you might get different results on different runs. Setting a random seed (like seed=123 in the code) ensures that the random processes in your code (e.g., shuffling data or initializing weights) are the same every time you run the model. This way, you can replicate results and debug issues more easily.\n",
        "3. Shuffle the Dataset\n",
        "Definition: Shuffling the dataset means randomizing the order of the data samples before they are fed into the model for training.\n",
        "Purpose: Shuffling is important to ensure that the model does not learn any unintended patterns based on the order of the data (e.g., if all images of one class appear consecutively). Randomizing the input helps the model generalize better and improves performance."
      ],
      "metadata": {
        "id": "MHsYc1QK8n53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "test_dir = '/content/asl_alphabet/asl_alphabet_test/asl_alphabet_test/'\n",
        "train_dir = '/content/asl_alphabet/asl_alphabet_train/asl_alphabet_train/'\n",
        "\n",
        "# Set image parameters\n",
        "IMG_HEIGHT, IMG_WIDTH = 200, 200\n",
        "BATCH_SIZE = 32  # Adjust as needed\n",
        "SEED = 123  # Set the seed for reproducibility\n",
        "\n",
        "# Load training data\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,  # Shuffle the training data\n",
        "    seed=SEED  # Set the seed for reproducibility\n",
        ")\n",
        "\n",
        "# Load testing data\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,  # Shuffle the training data\n",
        "    seed=SEED  # Set the seed for reproducibility\n",
        ")\n",
        "\n",
        "# Check the class names\n",
        "class_names = train_ds.class_names\n",
        "print(\"Class names:\", class_names)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KLiOxsKZyF9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding missing testing image"
      ],
      "metadata": {
        "id": "is0RhxiasJZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Count test images per class\n",
        "for class_name in class_names:\n",
        "    class_path = os.path.join(test_dir, class_name)\n",
        "    num_images = len(os.listdir(class_path)) if os.path.exists(class_path) else 0\n",
        "    print(f\"{class_name}: {num_images} images\")"
      ],
      "metadata": {
        "id": "maqz36LzFvtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Augmenting the missing testing image"
      ],
      "metadata": {
        "id": "vx0m1VN7s-G5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augment the Test Dataset: select the a random image from training dataset to be in the test set"
      ],
      "metadata": {
        "id": "qFLBHDYfGn5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Define paths\n",
        "train_dir = '/content/asl_alphabet/asl_alphabet_train/asl_alphabet_train/'\n",
        "test_dir = '/content/asl_alphabet/asl_alphabet_test/asl_alphabet_test/'\n",
        "\n",
        "# Specify the class that needs an image\n",
        "class_name = 'del'  # 'delete' class\n",
        "\n",
        "# Define the paths for the training and test class directories\n",
        "train_class_path = os.path.join(train_dir, class_name)\n",
        "test_class_path = os.path.join(test_dir, class_name)\n",
        "\n",
        "# Create the test class directory if it doesn't exist\n",
        "os.makedirs(test_class_path, exist_ok=True)\n",
        "\n",
        "# Get all images in the training class folder\n",
        "train_images = [img for img in os.listdir(train_class_path) if img.endswith('.jpg')]\n",
        "\n",
        "if train_images:\n",
        "    # Randomly select an image\n",
        "    random_image = random.choice(train_images)\n",
        "\n",
        "    # Define source and destination paths with the new name\n",
        "    src_path = os.path.join(train_class_path, random_image)\n",
        "    dest_path = os.path.join(test_class_path, f\"{class_name}_test.jpg\")\n",
        "\n",
        "    # Move the image from train to test and rename\n",
        "    shutil.move(src_path, dest_path)\n",
        "    print(f\"Moved {random_image} from {class_name} training set to test set as {class_name}_test.jpg.\")\n",
        "else:\n",
        "    print(f\"No images found in {class_name} training set.\")\n"
      ],
      "metadata": {
        "id": "zl78E5odGf6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Your Model: If you're ready, you can start building your model to train on the dataset."
      ],
      "metadata": {
        "id": "BVXWvGaXHE0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "id": "ZTziRh0G0Qwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Initialize MediaPipe hands\n",
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1)\n",
        "\n",
        "# Define directories\n",
        "train_dir = '/content/asl_alphabet/asl_alphabet_train/asl_alphabet_train/'\n",
        "output_dir = '/content/asl_alphabet/hand_landmarks/'\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Process images in the training directory\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "\n",
        "    for image_name in os.listdir(class_dir):\n",
        "        image_path = os.path.join(class_dir, image_name)\n",
        "\n",
        "        # Read the image\n",
        "        image = cv2.imread(image_path)\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Process the image to find hands\n",
        "        results = hands.process(image_rgb)\n",
        "\n",
        "        if results.multi_hand_landmarks:\n",
        "            for hand_landmarks in results.multi_hand_landmarks:\n",
        "                # Create a list of landmarks\n",
        "                landmarks = [(lm.x, lm.y, lm.z) for lm in hand_landmarks.landmark]\n",
        "\n",
        "                # Save landmarks as a numpy array or other format\n",
        "                landmarks_array = np.array(landmarks).flatten()  # Flatten the landmarks\n",
        "\n",
        "                # Define output path for landmarks\n",
        "                output_file = os.path.join(output_dir, f\"{class_name}_{image_name}.npy\")\n",
        "                np.save(output_file, landmarks_array)\n",
        "        else:\n",
        "            print(f\"No hands detected in {image_name}\")\n"
      ],
      "metadata": {
        "id": "grFspfka0R2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "use MediaPipeâ€™s hands module to detect hand landmarks in your training images.\n",
        "\n",
        "Processing Images: For each image in your training dataset:\n",
        "It reads the image and converts it to RGB (MediaPipe expects RGB input).\n",
        "It processes the image to find hand landmarks.\n",
        "If hand landmarks are found, they are extracted and saved as a flattened NumPy array.\n",
        "The output is saved in a specified directory with a unique filename."
      ],
      "metadata": {
        "id": "XaAm6qXR0Xf-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Your Model\n",
        "After extracting landmarks from your images, you can use the resulting files (e.g., .npy) as input features for training your model. The training labels can still be derived from your original dataset."
      ],
      "metadata": {
        "id": "veFwKs3O0i9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a Model\n",
        "You can now build and train your model using frameworks like TensorFlow or PyTorch. For example:"
      ],
      "metadata": {
        "id": "Q4JuimGg0oJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load your data (X: landmarks, y: labels)\n",
        "# Implement your data loading logic here\n",
        "\n",
        "# Build your model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(landmark_dim,)),  # Adjust landmark_dim\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')  # num_classes based on your dataset\n",
        "])\n",
        "\n",
        "# Compile and train your model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=10, batch_size=32)  # Adjust epochs and batch_size as needed\n"
      ],
      "metadata": {
        "id": "ayPiNo8c0o5j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}